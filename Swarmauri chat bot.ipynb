{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "220e88b3-9d60-402d-914c-ce31421bc05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swarmauri==0.4.1 in c:\\users\\ibk\\anaconda3\\lib\\site-packages (from swarmauri[full]==0.4.1) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\ibk\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ibk\\anaconda3\\lib\\site-packages (from swarmauri==0.4.1->swarmauri[full]==0.4.1) (1.26.4)\n",
      "Requirement already satisfied: requests in c:\\users\\ibk\\anaconda3\\lib\\site-packages (from swarmauri==0.4.1->swarmauri[full]==0.4.1) (2.32.2)\n",
      "Requirement already satisfied: pydantic in c:\\users\\ibk\\anaconda3\\lib\\site-packages (from swarmauri==0.4.1->swarmauri[full]==0.4.1) (2.5.3)\n",
      "Collecting ai21>=2.2.0 (from swarmauri[full]==0.4.1)\n",
      "  Using cached ai21-2.14.1-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting shuttleai (from swarmauri[full]==0.4.1)\n",
      "  Using cached shuttleai-4.7.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: transformers in c:\\users\\ibk\\anaconda3\\lib\\site-packages (from swarmauri[full]==0.4.1) (4.44.2)\n",
      "Collecting tensorflow (from swarmauri[full]==0.4.1)\n",
      "  Using cached tensorflow-2.17.0-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ibk\\anaconda3\\lib\\site-packages (from swarmauri[full]==0.4.1) (4.11.0)\n",
      "Collecting google-api-python-client (from swarmauri[full]==0.4.1)\n",
      "  Using cached google_api_python_client-2.145.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth-httplib2 (from swarmauri[full]==0.4.1)\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-oauthlib (from swarmauri[full]==0.4.1)\n",
      "  Using cached google_auth_oauthlib-1.2.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting boto3 (from swarmauri[full]==0.4.1)\n",
      "  Downloading boto3-1.35.20-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting yake (from swarmauri[full]==0.4.1)\n",
      "  Using cached yake-0.4.8-py2.py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\ibk\\anaconda3\\lib\\site-packages (from swarmauri[full]==0.4.1) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ibk\\anaconda3\\lib\\site-packages (from swarmauri[full]==0.4.1) (1.4.2)\n",
      "Requirement already satisfied: gensim in c:\\users\\ibk\\anaconda3\\lib\\site-packages (from swarmauri[full]==0.4.1) (4.3.2)\n",
      "Collecting textblob (from swarmauri[full]==0.4.1)\n",
      "  Using cached textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting spacy==3.7.4 (from swarmauri[full]==0.4.1)\n",
      "  Using cached spacy-3.7.4-cp312-cp312-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: pygments in c:\\users\\ibk\\anaconda3\\lib\\site-packages (from swarmauri[full]==0.4.1) (2.15.1)\n",
      "Requirement already satisfied: gradio in c:\\users\\ibk\\anaconda3\\lib\\site-packages (from swarmauri[full]==0.4.1) (4.44.0)\n",
      "Requirement already satisfied: websockets in c:\\users\\ibk\\anaconda3\\lib\\site-packages (from swarmauri[full]==0.4.1) (12.0)\n",
      "Collecting openai (from swarmauri[full]==0.4.1)\n",
      "  Downloading openai-1.45.1-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting groq (from swarmauri[full]==0.4.1)\n",
      "  Using cached groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting mistralai (from swarmauri[full]==0.4.1)\n",
      "  Using cached mistralai-1.0.3-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting cohere (from swarmauri[full]==0.4.1)\n",
      "  Using cached cohere-5.9.2-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting google-generativeai (from swarmauri[full]==0.4.1)\n",
      "  Using cached google_generativeai-0.8.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting anthropic (from swarmauri[full]==0.4.1)\n",
      "  Using cached anthropic-0.34.2-py3-none-any.whl.metadata (18 kB)\n",
      "INFO: pip is looking at multiple versions of swarmauri[full] to determine which version is compatible with other requirements. This could take a while.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following yanked versions: 1.11.0, 1.14.0rc1\n",
      "ERROR: Ignored the following versions that require a different python version: 1.10.0 Requires-Python <3.12,>=3.8; 1.10.0rc1 Requires-Python <3.12,>=3.8; 1.10.0rc2 Requires-Python <3.12,>=3.8; 1.10.1 Requires-Python <3.12,>=3.8; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11; 1.9.0 Requires-Python >=3.8,<3.12; 1.9.0rc1 Requires-Python >=3.8,<3.12; 1.9.0rc2 Requires-Python >=3.8,<3.12; 1.9.0rc3 Requires-Python >=3.8,<3.12; 1.9.1 Requires-Python >=3.8,<3.12; 4.0.0 Requires-Python >=3.7,<3.11\n",
      "ERROR: Could not find a version that satisfies the requirement scipy==1.10.0; extra == \"full\" (from swarmauri[full]) (from versions: 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.16.1, 0.17.0, 0.17.1, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 1.0.0, 1.0.1, 1.1.0, 1.2.0, 1.2.1, 1.2.2, 1.2.3, 1.3.0, 1.3.1, 1.3.2, 1.3.3, 1.4.0, 1.4.1, 1.5.0, 1.5.1, 1.5.2, 1.5.3, 1.5.4, 1.6.0, 1.6.1, 1.9.2, 1.9.3, 1.11.0rc1, 1.11.0rc2, 1.11.1, 1.11.2, 1.11.3, 1.11.4, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.13.0rc1, 1.13.0, 1.13.1, 1.14.0rc2, 1.14.0, 1.14.1)\n",
      "ERROR: No matching distribution found for scipy==1.10.0; extra == \"full\"\n"
     ]
    }
   ],
   "source": [
    "# install libraries\n",
    "! pip install swarmauri[full]==0.4.1 python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a0094f5-4d5b-414b-8c46-8d318be07acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import gradio as gr\n",
    "from swarmauri.standard.llms.concrete.GroqModel import GroqModel\n",
    "from swarmauri.standard.messages.concrete.SystemMessage import SystemMessage\n",
    "from swarmauri.standard.agents.concrete.SimpleConversationAgent import SimpleConversationAgent\n",
    "from swarmauri.standard.conversations.concrete.MaxSystemContextConversation import MaxSystemContextConversation\n",
    "\n",
    "#load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "#fetch the API key from environment variables\n",
    "API_KEY =os.getenv(\"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\")\n",
    "\n",
    "#initialize the Groqmodel with the API key to access allowed models\n",
    "llm = GroqModel (api_key=\"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\")\n",
    "\n",
    "#get the available models from the llm instance\n",
    "allowed_models = llm.allowed_models\n",
    "\n",
    "#initailize a MaxSystemContextConversation instance\n",
    "conversation = MaxSystemContextConversation()\n",
    "\n",
    "#define a function to dynamically change the model based on dropdown input\n",
    "def load_model(selected_model):\n",
    "    return GroqModel(api_key=\"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\", name=selected_model)\n",
    "\n",
    "#define the function to interact with the agent\n",
    "def converse(input_text, history, system_context, model_name):\n",
    "    print(f\"system_context: {system_context}\")\n",
    "    print(f\"selected_model: {model_name}\")\n",
    "\n",
    "    #initialize the model dynamically based on user selection\n",
    "    llm = load_model(model_name)\n",
    "\n",
    "    #initialize the agent with the new model\n",
    "    agent = SimpleConversationAgent(llm=llm, conversation=conversation)\n",
    "    \n",
    "    agent.conversation.system_context = SystemMessage(content=system_context)\n",
    "\n",
    "    #ensure input_text is a string\n",
    "    input_text = str(input_text)\n",
    "    print(conversation.history)\n",
    "    \n",
    "    #execute the input command with the agent\n",
    "    result = agent.exec(input_text)\n",
    "    print(result, type(result))\n",
    "\n",
    "    #return the result as a string\n",
    "    return str(result)\n",
    "\n",
    "#set up the gradio chatinterface with a dropdown for model selection\n",
    "demo = gr.ChatInterface(\n",
    "    fn=converse,\n",
    "    additional_inputs=[\n",
    "        gr.Textbox(label=\"System Context\"),\n",
    "        gr.Dropdown(label=\"Model Name\", choices=allowed_models, value=allowed_models[0])\n",
    "    ],\n",
    "    title=\"A System Context Conversation\",\n",
    "    description=\"Interact with the agent using selected model and system context.\"\n",
    ")\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe3d3f52-bd45-4ad3-8579-4e37e6323288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def chatbot_response(message):\n",
    "    # Your chatbot logic here\n",
    "    return \"Response from chatbot\"\n",
    "\n",
    "interface = gr.Interface(fn=chatbot_response, inputs=\"text\", outputs=\"text\")\n",
    "interface.launch(share=True)  # Set share=True to get a public URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263db6a5-c39b-4c56-af45-2275b30c614a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarmauri(0.4.1)",
   "language": "python",
   "name": "swarmauri-0.4.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
